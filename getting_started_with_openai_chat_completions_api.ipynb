{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okj3031402/LLM_study/blob/main/getting_started_with_openai_chat_completions_api.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "OpenAI API(챗 완성) 사용해보기\n",
        "\n",
        "- 텍스트 완성 : 안녕 > llm > 하세요.\n",
        "- 챗 완성 : 안녕 > llm > 안녕하세요."
      ],
      "metadata": {
        "id": "u-KIIvQ5NKJP"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GHgrhVbLnM6I",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "51877cbd-aa28-43fc-9c7f-fb8686320f65"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.30.1-py3-none-any.whl (320 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/320.6 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m122.9/320.6 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m320.6/320.6 kB\u001b[0m \u001b[31m4.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m4.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m6.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.30.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai # openai 라이브러리를 설치합니다."
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import openai\n",
        "from google.colab import userdata\n",
        "\n",
        "openai.api_key = userdata.get('OPENAI_API_KEY')"
      ],
      "metadata": {
        "id": "C5uYZQknXLDM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# OpenAI 모델\n",
        "\n",
        "[자세히 보기](https://platform.openai.com/docs/models/gpt-3-5-turbo)"
      ],
      "metadata": {
        "id": "_iCv35pk8-ok"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.chat.completions.create(\n",
        "    model = \"gpt-3.5-turbo\",\n",
        "    messages =\n",
        "    [\n",
        "        {\"role\": \"system\", \"content\": \"You are a helpful assistant. You must reply in Korean.\"},\n",
        "        {\"role\": \"user\", \"content\": \"hello~\"}\n",
        "    ]\n",
        ")\n",
        "\n",
        "# 편지지의 종류 system, user, assistant, function (편지지를 쓰는 주제, 정보 제공자)\n",
        "# - system : 역할부여 프롬프팅, 지시문, 퓨샷, 지문\n",
        "# - user : 서비스 시에 사용자가 입력하는 문장\n",
        "# - assistant : GPT가 생성하는 문장\n",
        "# - function : 함수나 API 호출 결과\n",
        "# 위 항목은 \"role\"이라는 키에 저장합니다."
      ],
      "metadata": {
        "id": "YbHPPNAbF6WE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion) # AI가 준 편지봉투\n",
        "\n",
        "# role='assistant' 인 경우 두가지 케이스가 있습니다.\n",
        "# content가 내용이 존재하고, function_call이 None인 경우\n",
        "# content가 None, function_call에 내용(function_name, function_argument)이 있는 경우"
      ],
      "metadata": {
        "id": "_b7iN1dXYxry",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ec9584d5-f18d-44f1-bef2-c0e3d83c0450"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletion(id='chatcmpl-9POufhIKWfDxkNAo9A7JYO15M3vhv', choices=[Choice(finish_reason='stop', index=0, logprobs=None, message=ChatCompletionMessage(content='안녕하세요~ 어떻게 도와드릴까요?', role='assistant', function_call=None, tool_calls=None))], created=1715840993, model='gpt-3.5-turbo-0125', object='chat.completion', system_fingerprint=None, usage=CompletionUsage(completion_tokens=22, prompt_tokens=25, total_tokens=47))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "n 옵션 살펴보기\n",
        "\n",
        "\n",
        "```\n",
        "n\n",
        "integer or null\n",
        "\n",
        "Optional\n",
        "Defaults to 1\n",
        "How many chat completion choices to generate for each input message. Note that you will be charged based on the number of generated tokens across all of the choices. Keep n as 1 to minimize costs.\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "GCIJ4LcNbZV6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "completion = openai.chat.completions.create(\n",
        "  model = \"gpt-4-turbo\",\n",
        "  messages=[\n",
        "    {\"role\": \"system\", \"content\": \"You are a helpful assistant.\"},\n",
        "    {\"role\": \"user\", \"content\": \"Hi\"}\n",
        "  ],\n",
        "  n = 3,\n",
        "  temperature = 2.0,\n",
        ")\n",
        "\n",
        "for choice in completion.choices:\n",
        "    print(choice.message)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GC1oTvaDbJFP",
        "outputId": "731f8cbc-ec57-4616-a7d9-469437eb978f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n",
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n",
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 생각해보기\n",
        "\n",
        "'user' 대신에 다른 role 넣어보기\n",
        "\n",
        "```\n",
        "BadRequestError: Error code: 400 - {'error': {'message': \"'user1' is not one of ['system', 'assistant', 'user', 'function'] - 'messages.1.role'\", 'type': 'invalid_request_error', 'param': None, 'code': None}}\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "9-pHaI0R6Q1F"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 메시지 꺼내기"
      ],
      "metadata": {
        "id": "QngicV-cNgkS"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message)"
      ],
      "metadata": {
        "id": "jgGxyxRMYSRZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "52c340ca-872c-4d34-e9e9-d33b577e18e2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ChatCompletionMessage(content='Hello! How can I assist you today?', role='assistant', function_call=None, tool_calls=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(completion.choices[0].message.content)"
      ],
      "metadata": {
        "id": "XBHm_aWCnIpH",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1358d25a-78b7-4867-9083-706445371e46"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Hello! How can I assist you today?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 토큰이란?\n",
        "\n",
        "- 텍스트를 바로 모델에 입력할 수 없기 때문에, 사전을 만들고 ID를 발급해야 한다.\n",
        "- 입력되는 텍스트를 어떤 기준으로 나누는 것.\n",
        "- 어떤 기준이란 토큰나이저에 따라 다르다.\n",
        "\n",
        "- 안녕하세요. > 안녕 | 하세요.\n",
        "- 안녕하세요. > 안 | 녕 | 하세요.\n",
        "- 안녕하세요. > 안 | 녕 | 하 | 세요 |.\n",
        "- 안녕하세요. > 안 | 녕 | 하 | 세 | 요 |.\n",
        "- 안녕하세요. > ㅇ | ㅏ | ㄴ |..\n",
        "\n",
        "OpenAI 토크나이저 [보기](https://platform.openai.com/tokenizer)"
      ],
      "metadata": {
        "id": "2S1VYwHN6WAt"
      }
    }
  ]
}