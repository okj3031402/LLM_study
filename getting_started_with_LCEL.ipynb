{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/okj3031402/LLM_study/blob/main/getting_started_with_LCEL.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VdKDqIJGxXo",
        "outputId": "367f01ea-889f-417e-e5df-15d258c73c06"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: langchain in /usr/local/lib/python3.10/dist-packages (0.1.20)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.30)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Requirement already satisfied: dataclasses-json<0.7,>=0.5.7 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.6.6)\n",
            "Requirement already satisfied: langchain-community<0.1,>=0.0.38 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.38)\n",
            "Requirement already satisfied: langchain-core<0.2.0,>=0.1.52 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.52)\n",
            "Requirement already satisfied: langchain-text-splitters<0.1,>=0.0.1 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.0.2)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.17 in /usr/local/lib/python3.10/dist-packages (from langchain) (0.1.59)\n",
            "Requirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.1)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.3.0)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (3.21.2)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7,>=0.5.7->langchain) (0.9.0)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (1.33)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.2.0,>=0.1.52->langchain) (23.2)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.17->langchain) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.2)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.2.0,>=0.1.52->langchain) (2.4)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain) (1.0.0)\n",
            "Requirement already satisfied: openai in /usr/local/lib/python3.10/dist-packages (1.30.1)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai) (0.27.0)\n",
            "Requirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.1)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai) (0.14.0)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.2)\n",
            "Requirement already satisfied: langchain_openai in /usr/local/lib/python3.10/dist-packages (0.1.7)\n",
            "Requirement already satisfied: langchain-core<0.3,>=0.1.46 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.1.52)\n",
            "Requirement already satisfied: openai<2.0.0,>=1.24.0 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (1.30.1)\n",
            "Requirement already satisfied: tiktoken<1,>=0.7 in /usr/local/lib/python3.10/dist-packages (from langchain_openai) (0.7.0)\n",
            "Requirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (6.0.1)\n",
            "Requirement already satisfied: jsonpatch<2.0,>=1.33 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (1.33)\n",
            "Requirement already satisfied: langsmith<0.2.0,>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (0.1.59)\n",
            "Requirement already satisfied: packaging<24.0,>=23.2 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (23.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (2.7.1)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain-core<0.3,>=0.1.46->langchain_openai) (8.3.0)\n",
            "Requirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.7.0)\n",
            "Requirement already satisfied: httpx<1,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (0.27.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.66.4)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai<2.0.0,>=1.24.0->langchain_openai) (4.11.0)\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2023.12.25)\n",
            "Requirement already satisfied: requests>=2.26.0 in /usr/local/lib/python3.10/dist-packages (from tiktoken<1,>=0.7->langchain_openai) (2.31.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.2.1)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (2024.2.2)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (1.0.5)\n",
            "Requirement already satisfied: h11<0.15,>=0.13 in /usr/local/lib/python3.10/dist-packages (from httpcore==1.*->httpx<1,>=0.23.0->openai<2.0.0,>=1.24.0->langchain_openai) (0.14.0)\n",
            "Requirement already satisfied: jsonpointer>=1.9 in /usr/local/lib/python3.10/dist-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.46->langchain_openai) (2.4)\n",
            "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in /usr/local/lib/python3.10/dist-packages (from langsmith<0.2.0,>=0.1.0->langchain-core<0.3,>=0.1.46->langchain_openai) (3.10.3)\n",
            "Requirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.2 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.46->langchain_openai) (2.18.2)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (3.3.2)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests>=2.26.0->tiktoken<1,>=0.7->langchain_openai) (2.0.7)\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain\n",
        "!pip install openai\n",
        "!pip install langchain_openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LP4vp6xXpFrN"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import openai\n",
        "\n",
        "from google.colab import userdata\n",
        "os.environ[\"OPENAI_API_KEY\"] = userdata.get('OPENAI_API_KEY')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WCyakdVyKbgp"
      },
      "outputs": [],
      "source": [
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "\n",
        "# 객체를 생성합니다.\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "chat_model = ChatOpenAI()\n",
        "output_parser = StrOutputParser() # Message의 content를 추출해서 string으로 변환\n",
        "\n",
        "# 체인을 정의합니다. (호출은 아직 하지 않았습니다.)\n",
        "chain = chat_prompt_template | chat_model | output_parser"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "6RoW7-0_1VUm"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NOmFdnFYu69R",
        "outputId": "810c7c29-eb56-4d54-b674-c980ae6fdfeb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ChatPromptTemplate(input_variables=['topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['topic'], template='tell me a short joke about {topic}'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x7864359f9bd0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x7864359f9270>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 47
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke 인자로 dict를 넘깁니다.\n",
        "# 그 이유가 prompt_template이 dict를 받기 때문입니다.\n",
        "\n",
        "chain.invoke({\"topic\": \"ice cream\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6grFdlXFcObi",
        "outputId": "2d851c74-693c-491b-e795-c70f9417bde2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream truck break down? \\n\\nBecause it had too many \"scoops\"!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 객체를 따로 생성하지 않고, 체인 정의할 때 바로 생성자를 이용\n",
        "\n",
        "chain = chat_prompt_template | ChatOpenAI() | StrOutputParser()\n",
        "chain.invoke({\"topic\": \"ice cream\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2s8fShzX1Wts",
        "outputId": "75025ba9-c898-4950-cee3-bb067818fbcf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream cone go to therapy? Because it had too many toppings!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### dict말고 \"ice cream\"만 넣고 싶을 때"
      ],
      "metadata": {
        "id": "OUDdNtJIxfa2"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "chat_model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "chain = {\"topic\": RunnablePassthrough()} | chat_prompt_template | chat_model | output_parser"
      ],
      "metadata": {
        "id": "TSEzYgZowP-R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke할 때, 굳이 topic 키로 dict로 넣어야 하나? 그냥 문자열로 넣으면 안될까?\n",
        "# 문자열을 받아서, chain에 전달됨\n",
        "# prompt_template의 입력 형식 dict로 받아야한다.\n",
        "# 인자를 value로 dict를 구성해서 넘거야겠다.\n",
        "# \"ice cream\" > RunnablePassthrough() > {\"topic\": RunnablePassthrough()} > prompt_template\n",
        "\n",
        "chain.invoke(\"ice cream\")\n",
        "\n",
        "# RunnablePassthrough() = \"ice cream\"\n",
        "\n",
        "# 질문 : RunnablePassthrough() 형식이 문자열인가요?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jtq6IM4W7hJ7",
        "outputId": "00a2a53e-8df7-4525-ea9c-7f36cd08b56b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream truck break down? Because it had too many \"scoops\" on board!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 답 : invoke의 형식을 그대로 따릅니다. 만약 문자열이면 문자열, dict이면 dict입니다.\n",
        "\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_core.runnables import RunnablePassthrough, RunnableParallel, RunnableLambda\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
        "chat_model = ChatOpenAI()\n",
        "output_parser = StrOutputParser()\n",
        "\n",
        "# 이렇게도 가능합니다.\n",
        "chain = RunnablePassthrough() | prompt_template | chat_model | output_parser\n",
        "\n",
        "chain.invoke({\"topic\": \"ice cream\"})"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3VM3a27B8QHh",
        "outputId": "2302d2bc-0454-4480-eeb2-d66e0d2e8d9d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'Why did the ice cream truck break down? Because it had too many \"scoops\"!'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "```\n",
        "# object approach\n",
        "chain = a.__or__(b)\n",
        "chain(\"some input\")\n",
        "\n",
        "# pipe approach\n",
        "chain = a | b\n",
        "chain(\"some input\")\n",
        "\n",
        "```\n",
        "\n"
      ],
      "metadata": {
        "id": "Y621fdW6dfY5"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Runnable:\n",
        "\n",
        "    def __init__(self, func):\n",
        "        self.func = func\n",
        "\n",
        "    # 이 메서드는 파이썬의 비트 OR 연산자(|)를 오버로드합니다.\n",
        "    def __or__(self, other):\n",
        "\n",
        "        def chained_func(*args, **kwargs):\n",
        "            # the other func consumes the result of this func\n",
        "            return other(self.func(*args, **kwargs))\n",
        "\n",
        "        return Runnable(chained_func)\n",
        "\n",
        "    def __call__(self, *args, **kwargs):\n",
        "        return self.func(*args, **kwargs)"
      ],
      "metadata": {
        "id": "eQ7_Yb65bIpJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def add_five(x):\n",
        "    return x + 5\n",
        "\n",
        "def multiply_by_two(x):\n",
        "    return x * 2"
      ],
      "metadata": {
        "id": "OBMlj0tkbM-H"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# wrap the functions with Runnable\n",
        "add_five = Runnable(add_five)\n",
        "multiply_by_two = Runnable(multiply_by_two)"
      ],
      "metadata": {
        "id": "KdwcLqVJbOS_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# chain the runnable functions together\n",
        "chain = add_five | multiply_by_two"
      ],
      "metadata": {
        "id": "6kfPseF3_dBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# invoke the chain\n",
        "chain(3)  # we should return ??"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zeFvGwGZ_eVH",
        "outputId": "80c7cd02-7ce4-4ee4-9743-bd0cfd0342d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# run them using the object approach\n",
        "chain = add_five.__or__(multiply_by_two)\n",
        "chain(3)  # should return 16"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Rg3ciXXqHCCi",
        "outputId": "36234b9d-92a1-4056-d04e-577e68be9eff"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "16"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def num2ko(x):\n",
        "    return str(x) + \"입니다.\""
      ],
      "metadata": {
        "id": "WGXEWY7bItV2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain = add_five | multiply_by_two | num2ko"
      ],
      "metadata": {
        "id": "IOCma1nZI3g8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chain(3)\n",
        "\n",
        "# num2ko는 Runnable이 아닌데, 호출이 되나요?"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VDJt5MYkI4p0",
        "outputId": "b672be62-4957-4eac-e386-b234c6cbde2d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'16입니다.'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "# 템플릿 만드는 방법\n",
        "\n",
        "# 미션 : 어떤 주제에 대해서 사용자 레벨에 맞게 선택된 언어로 대화 예시를 만드는 앱을 개발!\n",
        "\n",
        "# 기획\n",
        "# \"Please generate dialogue sentences in English on the topic of health for a beginner level.\"\n",
        "# \"Please generate dialogue sentences in Korean on the topic of AI for an intermediate level.\"\n",
        "\n",
        "# 양식과 변수를 분리하기\n",
        "# \"Please generate three sentences in a dialogue in (English) on the topic of (health) for a (beginner) level.\"\n",
        "# \"Please generate three sentences in a dialogue in (Korean) on the topic of (AI) for an (intermediate) level.\"\n",
        "\n",
        "# \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a/an {level} level.\"\n",
        "\n",
        "# 양식 조정하기\n",
        "# \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\""
      ],
      "metadata": {
        "id": "mbKP6cxOiQLi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "template = \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = chat_prompt_template | chat_model | StrOutputParser()\n",
        "\n",
        "# 변수는 dict로 넣습니다.\n",
        "output = chain.invoke({\"language\" : \"English\", \"topic\" : \"travel\", \"level\" : \"beginner\"})\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "0CJg_YS9iSSs",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6a74a57c-2d16-4e41-eced-784a40e63121"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Person 1: \"Have you ever been on a plane before?\"\n",
            "Person 2: \"No, I haven't. I usually travel by car or bus.\"\n",
            "Person 1: \"You should try flying sometime. It's a faster way to get to faraway places.\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 변수 중에 시스템에서 입력해야할 것과 사용자가 입력해야할 것 분리\n",
        "# language : 설정\n",
        "# topic : 바뀐다.\n",
        "# level : 설정\n",
        "\n",
        "def get_learning_language(_):\n",
        "    print(\"###\")\n",
        "    print(_)\n",
        "    print(\"in get_learning_language\")\n",
        "    print(\"###\")\n",
        "    return \"English\"\n",
        "\n",
        "def get_learning_level(_):\n",
        "    print(\"###\")\n",
        "    print(_)\n",
        "    print(\"in get_learning_level\")\n",
        "    print(\"###\")\n",
        "    return \"beginner\"\n",
        "\n",
        "# 그럼 이 함수를 체인 내에서 어떻게 호출해야하는가?\n",
        "# 예시 ) 휴가 신청서 사용할 때, 신청일시, 이름 등이 자동으로 기입되는 것"
      ],
      "metadata": {
        "id": "WavqPIUFiUrR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "nswM46ePsmC1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 방법 1\n",
        "\n",
        "template = \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = prompt_template | chat_model| StrOutputParser()\n",
        "\n",
        "# invoke 하기 전에 필요한 정보를 dict로 구성하는 방법\n",
        "output = chain.invoke({\"language\" : get_learning_language(''), \"topic\" : \"travel\", \"level\" : get_learning_level('')})\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "-FI_nBMrUOR8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "de096443-bc6f-4a41-fb81-9c5383456799"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###\n",
            "\n",
            "in get_learning_language\n",
            "###\n",
            "###\n",
            "\n",
            "in get_learning_level\n",
            "###\n",
            "Person 1: Have you ever been to another country before?\n",
            "Person 2: No, I haven't. I want to travel to France one day.\n",
            "Person 1: That sounds like a great idea. I love traveling and experiencing new cultures.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 방법2\n",
        "\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "chat_prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "# 함수의 인자는 무조건 1개이어야 합니다.\n",
        "chain = (\n",
        "    RunnablePassthrough.assign(language = get_learning_language,\n",
        "                               level = get_learning_level)\n",
        "\n",
        "    | chat_prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "# {\"topic\" : \"travel\"} > dict language, level 추가 > {\"topic\", ... \"language\", ... \"level\" ...} dict가 완성\n",
        "# > prompt_template > chat_model\n",
        "\n",
        "output = chain.invoke({\"topic\" : \"travel\"}) # 변수 1개\n",
        "\n",
        "print(output)\n",
        "\n",
        "# 넘어오는 인자에 추가적으로 key와 value를 넣고 싶을 때, RunnablePassthrough을 사용한다."
      ],
      "metadata": {
        "id": "7zoOVeEuiW5w",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f1178835-c4b5-4b29-b603-dd9a60e50efb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "###\n",
            "{'topic': 'travel'}\n",
            "in get_learning_language\n",
            "###\n",
            "###\n",
            "{'topic': 'travel'}\n",
            "in get_learning_level\n",
            "###\n",
            "Person 1: \"Have you ever been on a plane before?\"\n",
            "Person 2: \"No, I haven't. But I want to travel to a new country soon.\"\n",
            "Person 1: \"That sounds exciting! Where do you want to go?\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "chain"
      ],
      "metadata": {
        "id": "0UCwGveJyklR",
        "outputId": "1c98283a-356f-4b23-e459-f4d7f232bb68",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RunnableAssign(mapper={\n",
              "  language: RunnableLambda(get_learning_language),\n",
              "  level: RunnableLambda(get_learning_level)\n",
              "})\n",
              "| ChatPromptTemplate(input_variables=['language', 'level', 'topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language', 'level', 'topic'], template='Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.'))])\n",
              "| ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x786434b5c9d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x786434d0c2e0>, openai_api_key=SecretStr('**********'), openai_proxy='')\n",
              "| StrOutputParser()"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "template = \"Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.\"\n",
        "\n",
        "prompt_template = ChatPromptTemplate.from_template(template)\n",
        "\n",
        "chain = (\n",
        "    {\"topic\" : RunnablePassthrough()}\n",
        "    | RunnablePassthrough.assign(language = get_learning_language,\n",
        "                                 level = get_learning_level)\n",
        "\n",
        "    | prompt_template\n",
        "    | chat_model\n",
        "    | StrOutputParser()\n",
        ")\n",
        "\n",
        "print(chain)\n",
        "\n",
        "output = chain.invoke(\"travel\")\n",
        "\n",
        "print(output)"
      ],
      "metadata": {
        "id": "T90SuR4IiY5C",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "90fcf397-e7c4-4472-9120-7f8ab5d6724f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "first={\n",
            "  topic: RunnablePassthrough()\n",
            "} middle=[RunnableAssign(mapper={\n",
            "  language: RunnableLambda(get_learning_language),\n",
            "  level: RunnableLambda(get_learning_level)\n",
            "}), ChatPromptTemplate(input_variables=['language', 'level', 'topic'], messages=[HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=['language', 'level', 'topic'], template='Please generate three sentences in a dialogue in {language} on the topic of {topic} for a level of {level}.'))]), ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x786434b5c9d0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x786434d0c2e0>, openai_api_key=SecretStr('**********'), openai_proxy='')] last=StrOutputParser()\n",
            "###\n",
            "{'topic': 'travel'}\n",
            "in get_learning_language\n",
            "###\n",
            "###\n",
            "{'topic': 'travel'}\n",
            "in get_learning_level\n",
            "###\n",
            "Person 1: Have you ever been on a plane before?\n",
            "\n",
            "Person 2: No, I haven't. But I want to travel to a different country someday.\n",
            "\n",
            "Person 1: That sounds exciting! Where would you like to go?\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "L0of1oNh4KAB"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}